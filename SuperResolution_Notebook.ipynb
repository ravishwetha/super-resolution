{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33YP-WmIRDAQ",
        "outputId": "c2b9d4b9-8f48-4d2a-a99f-f49e10bbb9e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43tXlcgd5xjQ",
        "outputId": "ffb8633f-a36a-4bcc-af0c-171104b8d9fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "import tensorflow as tf\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "if len(physical_devices) > 0:\n",
        "    device = physical_devices[0]\n",
        "\n",
        "    memory_limit = 80 * 1024  # 80 GB\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "    tf.config.set_logical_device_configuration(device, [\n",
        "        tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit)\n",
        "    ])\n",
        "\n",
        "# Print the device name.\n",
        "# print(\"Selected device:\", device.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-E0OsSD-DAw",
        "outputId": "a5174217-8ddd-4c22-e3f6-d3cd2c578fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision==0.16 in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16) (2.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchvision==0.16) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision==0.16) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision==0.16) (1.3.0)\n",
            "Name: torchvision\n",
            "Version: 0.16.0\n",
            "Summary: image and video datasets and models for torch deep learning\n",
            "Home-page: https://github.com/pytorch/vision\n",
            "Author: PyTorch Core Team\n",
            "Author-email: soumith@pytorch.org\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, pillow, requests, torch\n",
            "Required-by: basicsr, facexlib, fastai, gfpgan, realesrgan\n",
            "Requirement already satisfied: realesrgan in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: basicsr>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (1.4.2)\n",
            "Requirement already satisfied: facexlib>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (0.3.0)\n",
            "Requirement already satisfied: gfpgan>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (1.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from realesrgan) (1.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from realesrgan) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from realesrgan) (9.4.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (2.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from realesrgan) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from realesrgan) (4.66.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (0.18.3)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (2.31.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (1.11.4)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (2.17.0a20240426)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (0.40.2)\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->realesrgan) (1.4.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->realesrgan) (0.58.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->realesrgan) (12.4.127)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib>=0.2.5->realesrgan) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->realesrgan) (2.1.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib>=0.2.5->realesrgan) (0.41.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (2024.2.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (2024.4.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (24.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->realesrgan) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (1.62.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.4.2->realesrgan) (7.1.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.4.2->realesrgan) (4.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.4.2->realesrgan) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->basicsr>=1.4.2->realesrgan) (3.18.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (2.8.2)\n",
            "Requirement already satisfied: basicsr in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.18.3)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from basicsr) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from basicsr) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.31.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.11.4)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.17.0a20240426)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from basicsr) (4.66.2)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->basicsr) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (2024.2.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (2024.4.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (24.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.62.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (7.1.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (4.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->basicsr) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->basicsr) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision==0.16\n",
        "!pip show torchvision\n",
        "!pip install realesrgan\n",
        "!pip install basicsr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "PkE-2ycKt_ee",
        "outputId": "6448b6d7-ff9a-454e-8b5e-6bcc511c8251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "12.1\n",
            "Initial memory usage:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'allocated_bytes.all.current'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3893aa536a9e>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Print initial memory usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial memory usage:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mmemory_summary\u001b[0;34m(device, abbreviated)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_key\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubmetric_key\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"current\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0mpeak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"peak\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mallocated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"allocated\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'allocated_bytes.all.current'"
          ]
        }
      ],
      "source": [
        "import os, gc\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ[\"PYTORCH_USE_CUDA_DSA\"] = '1'\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = 'max_split_size_mb:128'\n",
        "\n",
        "import torch\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "# Print initial memory usage\n",
        "print(\"Initial memory usage:\")\n",
        "print(torch.cuda.memory_summary())\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Memory usage after gc.collect() and torch.cuda.empty_cache():\")\n",
        "print(torch.cuda.memory_summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItF340VLG9Dp",
        "outputId": "164ed633-0f50-4d7d-800c-492bad3b87c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-f/res doesn't exist\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def read_image(path):\n",
        "    img = Image.open(path)\n",
        "    img = np.array(img) / 255.\n",
        "\n",
        "    return img * 255\n",
        "\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse_value = np.mean((img1 - img2)**2)\n",
        "\n",
        "    return 20. * np.log10(255. / np.sqrt(mse_value))\n",
        "\n",
        "\n",
        "input_dir = sys.argv[1]\n",
        "output_dir = sys.argv[2]\n",
        "\n",
        "submit_dir = os.path.join(input_dir, 'res')\n",
        "truth_dir = os.path.join(input_dir, 'ref')\n",
        "\n",
        "if not os.path.isdir(submit_dir):\n",
        "    print(\"%s doesn't exist\" % submit_dir)\n",
        "\n",
        "if os.path.isdir(submit_dir) and os.path.isdir(truth_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    submit_dir_list = os.listdir(submit_dir)\n",
        "    if len(submit_dir_list) == 1:\n",
        "        submit_dir = os.path.join(submit_dir, \"%s\" % submit_dir_list[0])\n",
        "        assert os.path.isdir(submit_dir)\n",
        "\n",
        "    psnr_list = []\n",
        "    for idx in range(400):\n",
        "        pred_img = read_image(os.path.join(submit_dir, \"%05d.png\" % idx))\n",
        "        gt_img = read_image(os.path.join(truth_dir, \"%05d.png\" % idx))\n",
        "        psnr_list.append(psnr(pred_img, gt_img))\n",
        "\n",
        "    mean_psnr = np.mean(psnr_list)\n",
        "\n",
        "    # Create the evaluation score path\n",
        "    output_filename = os.path.join(output_dir, 'scores.txt')\n",
        "\n",
        "    with open(output_filename, 'w') as f3:\n",
        "        f3.write('PSNR: {}'.format(mean_psnr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1rjRcZtiHF1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b94f0da7-0a94-418d-b532-c613e4fcca84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "from basicsr.data.degradations import circular_lowpass_kernel, random_mixed_kernels\n",
        "from basicsr.data.transforms import augment\n",
        "from basicsr.utils import FileClient, get_root_logger, imfrombytes, img2tensor\n",
        "from basicsr.utils.registry import DATASET_REGISTRY\n",
        "from torch.utils import data as data\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "# Remove the registered class from the registry\n",
        "if 'FFHQsubDataset' in DATASET_REGISTRY._obj_map:\n",
        "    del DATASET_REGISTRY._obj_map['FFHQsubDataset']\n",
        "\n",
        "@DATASET_REGISTRY.register()\n",
        "class FFHQsubDataset(data.Dataset):\n",
        "    \"\"\"Modified from Dataset used for Real-ESRGAN model:\n",
        "    Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data.\n",
        "\n",
        "    It loads gt (Ground-Truth) images, and augments them.\n",
        "    It also generates blur kernels and sinc kernels for generating low-quality images.\n",
        "    Note that the low-quality images are processed in tensors on GPUS for faster processing.\n",
        "\n",
        "    Args:\n",
        "        opt (dict): Config for train datasets. It contains the following keys:\n",
        "            dataroot_gt (str): Data root path for gt.\n",
        "            meta_info (str): Path for meta information file.\n",
        "            io_backend (dict): IO backend type and other kwarg.\n",
        "            use_hflip (bool): Use horizontal flips.\n",
        "            use_rot (bool): Use rotation (use vertical flip and transposing h and w for implementation).\n",
        "            Please see more options in the codes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        super(FFHQsubDataset, self).__init__()\n",
        "        self.opt = opt\n",
        "        self.file_client = None\n",
        "        self.io_backend_opt = opt['io_backend']\n",
        "        self.gt_folder = opt['dataroot_gt']\n",
        "        self.lq_folder = opt.get('dataroot_lq', None)\n",
        "\n",
        "        # file client (lmdb io backend)\n",
        "        if self.io_backend_opt['type'] == 'lmdb':\n",
        "            self.io_backend_opt['db_paths'] = [self.gt_folder]\n",
        "            self.io_backend_opt['client_keys'] = ['gt']\n",
        "            if not self.gt_folder.endswith('.lmdb'):\n",
        "                raise ValueError(f\"'dataroot_gt' should end with '.lmdb', but received {self.gt_folder}\")\n",
        "            with open(osp.join(self.gt_folder, 'meta_info_FFHQ5000sub_GT.txt')) as fin:\n",
        "                self.paths = [line.split('.')[0] for line in fin]\n",
        "        else:\n",
        "            # disk backend with meta_info\n",
        "            # Each line in the meta_info describes the relative path to an image\n",
        "            with open(self.opt['meta_info']) as fin:\n",
        "                paths = [line.strip().split(' ')[0] for line in fin]\n",
        "                self.paths = [os.path.join(self.gt_folder, v) for v in paths]\n",
        "            self.gt_paths = [osp.join(self.gt_folder, p) for p in self.paths]\n",
        "            if self.lq_folder:\n",
        "                self.lq_paths = [osp.join(self.lq_folder, p) for p in self.paths]\n",
        "            else:\n",
        "                self.lq_paths = None\n",
        "\n",
        "        # blur settings for the first degradation\n",
        "        self.blur_kernel_size = opt['blur_kernel_size']\n",
        "        self.kernel_list = opt['kernel_list']\n",
        "        self.kernel_prob = opt['kernel_prob']  # a list for each kernel probability\n",
        "        self.blur_sigma = opt['blur_sigma']\n",
        "        self.betag_range = opt['betag_range']  # betag used in generalized Gaussian blur kernels\n",
        "        self.betap_range = opt['betap_range']  # betap used in plateau blur kernels\n",
        "        self.sinc_prob = opt['sinc_prob']  # the probability for sinc filters\n",
        "\n",
        "        # blur settings for the second degradation\n",
        "        self.blur_kernel_size2 = opt['blur_kernel_size2']\n",
        "        self.kernel_list2 = opt['kernel_list2']\n",
        "        self.kernel_prob2 = opt['kernel_prob2']\n",
        "        self.blur_sigma2 = opt['blur_sigma2']\n",
        "        self.betag_range2 = opt['betag_range2']\n",
        "        self.betap_range2 = opt['betap_range2']\n",
        "        self.sinc_prob2 = opt['sinc_prob2']\n",
        "\n",
        "        # a final sinc filter\n",
        "        self.final_sinc_prob = opt['final_sinc_prob']\n",
        "\n",
        "        self.kernel_range = [2 * v + 1 for v in range(3, 11)]  # kernel size ranges from 7 to 21\n",
        "        # TODO: kernel range is now hard-coded, should be in the configure file\n",
        "        self.pulse_tensor = torch.zeros(21, 21).float()  # convolving with pulse tensor brings no blurry effect\n",
        "        self.pulse_tensor[10, 10] = 1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # -------------------------------- Load gt images -------------------------------- #\n",
        "        # Shape: (h, w, c); channel order: BGR; image range: [0, 1], float32.\n",
        "        gt_path = self.paths[index]\n",
        "\n",
        "        # Read the image file directly from Google Drive\n",
        "        try:\n",
        "            with open(gt_path, 'rb') as f:\n",
        "                img_bytes = f.read()\n",
        "            img_gt = imfrombytes(img_bytes, float32=True)\n",
        "        except (IOError, OSError) as e:\n",
        "            logger = get_root_logger()\n",
        "            logger.warning(f'Failed to load image: {gt_path}. Error: {e}')\n",
        "            # Skip this image and move to the next one\n",
        "            return self.__getitem__(random.randint(0, self.__len__() - 1))\n",
        "\n",
        "        # -------------------- Do augmentation for training: flip, rotation -------------------- #\n",
        "        img_gt = augment(img_gt, self.opt['use_hflip'], self.opt['use_rot'])\n",
        "\n",
        "        # ------------------------ Generate kernels (used in the first degradation) ------------------------ #\n",
        "        kernel_size = random.choice(self.kernel_range)\n",
        "        if np.random.uniform() < self.opt['sinc_prob']:\n",
        "            # this sinc filter setting is for kernels ranging from [7, 21]\n",
        "            if kernel_size < 13:\n",
        "                omega_c = np.random.uniform(np.pi / 3, np.pi)\n",
        "            else:\n",
        "                omega_c = np.random.uniform(np.pi / 5, np.pi)\n",
        "            kernel = circular_lowpass_kernel(omega_c, kernel_size, pad_to=False)\n",
        "        else:\n",
        "            kernel = random_mixed_kernels(\n",
        "                self.kernel_list,\n",
        "                self.kernel_prob,\n",
        "                kernel_size,\n",
        "                self.blur_sigma,\n",
        "                self.blur_sigma, [-math.pi, math.pi],\n",
        "                self.betag_range,\n",
        "                self.betap_range,\n",
        "                noise_range=None)\n",
        "        # pad kernel\n",
        "        pad_size = (21 - kernel_size) // 2\n",
        "        kernel = np.pad(kernel, ((pad_size, pad_size), (pad_size, pad_size)))\n",
        "\n",
        "        # ------------------------ Generate kernels (used in the second degradation) ------------------------ #\n",
        "        kernel_size = random.choice(self.kernel_range)\n",
        "        if np.random.uniform() < self.opt['sinc_prob2']:\n",
        "            if kernel_size < 13:\n",
        "                omega_c = np.random.uniform(np.pi / 3, np.pi)\n",
        "            else:\n",
        "                omega_c = np.random.uniform(np.pi / 5, np.pi)\n",
        "            kernel2 = circular_lowpass_kernel(omega_c, kernel_size, pad_to=False)\n",
        "        else:\n",
        "            kernel2 = random_mixed_kernels(\n",
        "                self.kernel_list2,\n",
        "                self.kernel_prob2,\n",
        "                kernel_size,\n",
        "                self.blur_sigma2,\n",
        "                self.blur_sigma2, [-math.pi, math.pi],\n",
        "                self.betag_range2,\n",
        "                self.betap_range2,\n",
        "                noise_range=None)\n",
        "\n",
        "        # pad kernel\n",
        "        pad_size = (21 - kernel_size) // 2\n",
        "        kernel2 = np.pad(kernel2, ((pad_size, pad_size), (pad_size, pad_size)))\n",
        "\n",
        "        # ------------------------------------- the final sinc kernel ------------------------------------- #\n",
        "        if np.random.uniform() < self.opt['final_sinc_prob']:\n",
        "            kernel_size = random.choice(self.kernel_range)\n",
        "            omega_c = np.random.uniform(np.pi / 3, np.pi)\n",
        "            sinc_kernel = circular_lowpass_kernel(omega_c, kernel_size, pad_to=21)\n",
        "            sinc_kernel = torch.FloatTensor(sinc_kernel)\n",
        "        else:\n",
        "            sinc_kernel = self.pulse_tensor\n",
        "\n",
        "        # BGR to RGB, HWC to CHW, numpy to tensor\n",
        "        img_gt = img2tensor([img_gt], bgr2rgb=True, float32=True)[0]\n",
        "        kernel = torch.FloatTensor(kernel)\n",
        "        kernel2 = torch.FloatTensor(kernel2)\n",
        "\n",
        "        return_d = {'gt': img_gt, 'kernel1': kernel, 'kernel2': kernel2, 'sinc_kernel': sinc_kernel, 'gt_path': gt_path}\n",
        "\n",
        "        # Load low-quality image if available\n",
        "        if self.lq_paths:\n",
        "            lq_path = self.lq_paths[index]\n",
        "            try:\n",
        "                with open(lq_path, 'rb') as f:\n",
        "                    img_bytes = f.read()\n",
        "                img_lq = imfrombytes(img_bytes, float32=True)\n",
        "                img_lq = img2tensor([img_lq], bgr2rgb=True, float32=True)[0]\n",
        "            except (IOError, OSError) as e:\n",
        "                logger = get_root_logger()\n",
        "                logger.warning(f'Failed to load image: {lq_path}. Error: {e}')\n",
        "                img_lq = img_gt  # Use ground-truth image if low-quality image fails to load\n",
        "        else:\n",
        "            img_lq = img_gt  # Use ground-truth image if low-quality paths are not provided\n",
        "\n",
        "        return_d['lq'] = img_lq\n",
        "        return return_d\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "A7vBvucgE2oj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
        "from torchvision.transforms import GaussianBlur\n",
        "\n",
        "# Set the paths to the configuration file and dataset file\n",
        "config_path = '/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/train_SRResNet_x4_FFHQ_300k.yml'\n",
        "dataset_path = '/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/ffhqsub_dataset.py'\n",
        "\n",
        "# Set the paths to your train and validation data\n",
        "train_path = '/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/datasets/train'\n",
        "val_path = '/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/datasets/val'\n",
        "test_path = '/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/datasets/test'\n",
        "\n",
        "# Load the dataset module\n",
        "# import importlib.util\n",
        "# spec = importlib.util.spec_from_file_location(\"ffhqsub_dataset\", dataset_path)\n",
        "# dataset_module = importlib.util.module_from_spec(spec)\n",
        "# spec.loader.exec_module(dataset_module)\n",
        "# FFHQSubDataset = dataset_module.FFHQsubDataset\n",
        "\n",
        "# Define the SRResNet model architecture\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, num_feat=64):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv2(self.relu(self.conv1(x)))\n",
        "        return identity + out\n",
        "\n",
        "class SRResNet(nn.Module):\n",
        "    def __init__(self, num_in_ch=3, num_out_ch=3, num_feat=64, num_block=16, upscale=4):\n",
        "        super(SRResNet, self).__init__()\n",
        "        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\n",
        "        self.body = self.make_layer(ResidualBlock, num_block, num_feat)\n",
        "        self.conv_after_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.upsample = self.make_upsample_layer(upscale, num_feat)\n",
        "        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\n",
        "\n",
        "    def make_layer(self, block, num_blocks, num_feat):\n",
        "        layers = []\n",
        "        for _ in range(num_blocks):\n",
        "            layers.append(block(num_feat))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def make_upsample_layer(self, upscale, num_feat):\n",
        "        layers = []\n",
        "        for _ in range(int(torch.log(torch.tensor(upscale)).item() / torch.log(torch.tensor(2)).item())):\n",
        "            layers.append(nn.Conv2d(num_feat, 4 * num_feat, 3, 1, 1))\n",
        "            layers.append(nn.PixelShuffle(2))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.conv_first(x)\n",
        "        feat = self.body(feat)\n",
        "        feat = self.conv_after_body(feat)\n",
        "        feat = self.upsample(feat)\n",
        "        out = self.conv_last(feat)\n",
        "        return out\n",
        "\n",
        "# no mat mul issue\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_in_ch=3, num_feat=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(num_feat, num_feat * 2, 3, 2, 1)\n",
        "        self.conv3 = nn.Conv2d(num_feat * 2, num_feat * 4, 3, 2, 1)\n",
        "        self.conv4 = nn.Conv2d(num_feat * 4, num_feat * 8, 3, 2, 1)\n",
        "        self.conv5 = nn.Conv2d(num_feat * 8, 1, 3, 1, 1)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        self.fc = nn.Linear(65536, 1)  # Update the input size to match the largest flattened size\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.leaky_relu(self.conv1(x))\n",
        "#         print(\"After Conv1:\", x.shape)\n",
        "#         x = self.leaky_relu(self.conv2(x))\n",
        "#         print(\"After Conv2:\", x.shape)\n",
        "#         x = self.leaky_relu(self.conv3(x))\n",
        "#         print(\"After Conv3:\", x.shape)\n",
        "#         x = self.leaky_relu(self.conv4(x))\n",
        "#         print(\"After Conv4:\", x.shape)\n",
        "#         x = self.conv5(x)\n",
        "#         print(\"After Conv5:\", x.shape)\n",
        "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "#         print(\"After Flatten:\", x.shape)\n",
        "\n",
        "#         if x.size(1) != self.fc.in_features:\n",
        "#             self.fc = nn.Linear(x.size(1), 1)  # Dynamically adjust the input size of the fully connected layer\n",
        "\n",
        "#         x = self.fc(x)\n",
        "#         return torch.sigmoid(x)  # Apply sigmoid activation to the output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.conv1(x))\n",
        "        print(\"After Conv1:\", x.shape)\n",
        "        x = self.leaky_relu(self.conv2(x))\n",
        "        print(\"After Conv2:\", x.shape)\n",
        "        x = self.leaky_relu(self.conv3(x))\n",
        "        print(\"After Conv3:\", x.shape)\n",
        "        x = self.leaky_relu(self.conv4(x))\n",
        "        print(\"After Conv4:\", x.shape)\n",
        "        x = self.conv5(x)\n",
        "        print(\"After Conv5:\", x.shape)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        print(\"After Flatten:\", x.shape)\n",
        "\n",
        "        # Dynamically adjust the input size of the fully connected layer\n",
        "        if x.size(1) != self.fc.in_features:\n",
        "            self.fc = nn.Linear(x.size(1), 1)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)  # Apply sigmoid activation to the output\n",
        "\n",
        "# Load the model configuration\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "default_config = {\n",
        "    'io_backend': {'type': 'disk'},\n",
        "    'batch_size': 8,\n",
        "    'num_workers': 4,\n",
        "    'use_hflip': True,  # Typically, you might want to disable this for validation\n",
        "    'use_rot': True,    # Same as above\n",
        "    'blur_kernel_size': 21,\n",
        "    'kernel_list': ['iso', 'aniso'],\n",
        "    'kernel_prob': [0.5, 0.5],\n",
        "    'blur_sigma': [0.2, 3],\n",
        "    'betag_range': [0.5, 4],\n",
        "    'betap_range': [1, 2],\n",
        "    'sinc_prob': 0.1,\n",
        "    'blur_kernel_size2': 21,\n",
        "    'kernel_list2': ['iso', 'aniso'],\n",
        "    'kernel_prob2': [0.5, 0.5],\n",
        "    'blur_sigma2': [0.2, 1.5],\n",
        "    'betag_range2': [0.5, 4],\n",
        "    'betap_range2': [1, 2],\n",
        "    'sinc_prob2': 0.1,\n",
        "    'final_sinc_prob': 0.8,\n",
        "    'lr': 1e-4,\n",
        "    'num_epochs': 100\n",
        "}\n",
        "\n",
        "train_config = {\n",
        "    **default_config,\n",
        "    'dataroot_gt': f\"{train_path}/GT\",\n",
        "    'meta_info': f\"{train_path}/meta_info_FFHQ5000sub_GT.txt\",\n",
        "}\n",
        "\n",
        "val_config = {\n",
        "    **default_config,\n",
        "    'dataroot_gt': f\"{val_path}/GT\",\n",
        "    'dataroot_lq': f\"{val_path}/LQ\",\n",
        "    'meta_info': \"/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/val_meta_info_FFHQ5000sub_GT.txt\",\n",
        "    'use_hflip': False,  # Typically disable augmentation for validation\n",
        "    'use_rot': False\n",
        "}\n",
        "\n",
        "test_config = {\n",
        "    **default_config,\n",
        "    'dataroot_gt': f\"{test_path}/LQ\",\n",
        "    'meta_info': \"/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/test_meta_info_FFHQ5000sub_GT.txt\",\n",
        "    'use_hflip': False,  # Typically disable augmentation for testing\n",
        "    'use_rot': False\n",
        "}\n",
        "\n",
        "train_dataset = FFHQsubDataset(train_config)\n",
        "val_dataset = FFHQsubDataset(val_config)\n",
        "test_dataset = FFHQsubDataset(test_config)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_config['batch_size'], shuffle=True, num_workers=train_config['num_workers'])\n",
        "val_loader = DataLoader(val_dataset, batch_size=val_config['batch_size'], shuffle=False, num_workers=val_config['num_workers'])\n",
        "# test_real_loader = DataLoader(test_dataset, batch_size=test_config['batch_size'], shuffle=False, num_workers=test_config['num_workers'])\n",
        "test_loader = DataLoader(test_dataset, batch_size=test_config['batch_size'], shuffle=False, num_workers=test_config['num_workers'])\n",
        "\n",
        "model = SRResNet(num_in_ch=3, num_out_ch=3, num_feat=32, num_block=8, upscale=4)\n",
        "discriminator = Discriminator(num_in_ch=3, num_feat=64)\n",
        "\n",
        "criterion_l1 = nn.L1Loss()\n",
        "criterion_gan = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer_g = optim.Adam(model.parameters(), lr=1e-4)\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
        "\n",
        "def degrade_image(image, degradation_scale=0.5):\n",
        "    \"\"\"\n",
        "    Degrade the input image by downscaling and then upscaling, with Gaussian blurring.\n",
        "    Args:\n",
        "        image (torch.Tensor): The input image tensor.\n",
        "        degradation_scale (float): The factor to scale down and up the image.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The degraded image tensor.\n",
        "    \"\"\"\n",
        "    # Get the original dimensions\n",
        "    original_size = (image.size(2), image.size(3))\n",
        "\n",
        "    # # Calculate new size based on degradation scale\n",
        "    # new_size = (int(original_size[0] * degradation_scale), int(original_size[1] * degradation_scale))\n",
        "\n",
        "    # # Downscale and upscale to create a simple low-resolution version of the image\n",
        "    # downsampled = F.interpolate(image, size=new_size, mode='bilinear', align_corners=False)\n",
        "    # upsampled = F.interpolate(downsampled, size=original_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = GaussianBlur(kernel_size=(5, 5))(image)\n",
        "\n",
        "    return blurred\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_metadata_file(file_path):\n",
        "    # Open the original file in binary mode to check for BOM\n",
        "    with open(file_path, 'rb') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Remove the BOM (if any)\n",
        "    # BOM for UTF-8 encoded files\n",
        "    bom_utf8 = b'\\xef\\xbb\\xbf'\n",
        "    if content.startswith(bom_utf8):\n",
        "        content = content[len(bom_utf8):]\n",
        "\n",
        "    # Write the clean content back to the file\n",
        "    with open(file_path, 'wb') as file:\n",
        "        file.write(content)\n",
        "\n",
        "    print(f\"Cleaned metadata file: {file_path}\")\n",
        "\n",
        "# Clean the metadata files for train, val, and test datasets\n",
        "clean_metadata_file(val_config['meta_info'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0wwxb-eFBH1",
        "outputId": "5b1f5e9d-c7d3-4f9b-d17f-62d1ebfaba47"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned metadata file: /content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/val_meta_info_FFHQ5000sub_GT.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpbtSAhUVvs1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.cuda.set_per_process_memory_fraction(0.9, 0)\n",
        "\n",
        "num_epochs = 200\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "\n",
        "accumulation_steps = 2\n",
        "early_stopping_patience = 10\n",
        "early_stopping_counter = 0\n",
        "best_loss = float('inf')\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "optimizer_g = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_g, factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, batch_data in enumerate(train_loader):\n",
        "        gt_imgs = batch_data['gt'].to(device)\n",
        "        lq_imgs = degrade_image(gt_imgs).to(device)\n",
        "\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        sr_imgs = model(lq_imgs)\n",
        "        sr_imgs_resized = F.interpolate(sr_imgs, size=(gt_imgs.size(2), gt_imgs.size(3)), mode='bilinear', align_corners=False)\n",
        "        g_loss = criterion_l1(sr_imgs_resized, gt_imgs)\n",
        "\n",
        "        g_loss = g_loss / accumulation_steps\n",
        "        g_loss.backward()\n",
        "\n",
        "        if (batch_idx + 1) % accumulation_steps == 0:\n",
        "            optimizer_g.step()\n",
        "            optimizer_g.zero_grad()\n",
        "\n",
        "        train_loss += g_loss.item() * accumulation_steps\n",
        "\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_data in val_loader:\n",
        "            gt_imgs = batch_data['gt'].to(device)\n",
        "            lq_imgs = batch_data['lq'].to(device)\n",
        "            sr_imgs = model(lq_imgs)\n",
        "            sr_imgs_resized = F.interpolate(sr_imgs, size=(gt_imgs.size(2), gt_imgs.size(3)), mode='bilinear', align_corners=False)\n",
        "            val_loss += criterion_l1(sr_imgs_resized, gt_imgs).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        early_stopping_counter = 0\n",
        "        torch.save(model.state_dict(), f\"/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/model_2_{val_loss:.4f}.pth\")\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        if early_stopping_counter >= early_stopping_patience:\n",
        "            print(\"Stopping early due to lack of improvement in validation loss.\")\n",
        "            break\n",
        "\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curves')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "torch.save(model.state_dict(), f\"/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/model_final.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curves')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "KUEV6XickuL_",
        "outputId": "a84a14e2-fa44-4ef8-f092-a24ad6a7f054"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7b78e9eda690>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss Curves'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOl4sX6yBF-z"
      },
      "outputs": [],
      "source": [
        "# for epoch in range(num_epochs):\n",
        "#     model.train()\n",
        "#     train_loss = 0\n",
        "#     for batch_idx, batch_data in enumerate(train_loader):\n",
        "#         gt_imgs = batch_data['gt'].to(device)\n",
        "#         lq_imgs = degrade_image(gt_imgs)  # Generate LQ images on-the-fly\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         sr_imgs = model(lq_imgs)  # Super-resolve the LQ images\n",
        "#         sr_imgs_resized = F.interpolate(sr_imgs, size=(gt_imgs.size(2), gt_imgs.size(3)), mode='bilinear', align_corners=False)\n",
        "\n",
        "#         loss = criterion(sr_imgs_resized, gt_imgs)\n",
        "#         loss = loss / accumulation_steps  # Normalize the loss for gradient accumulation\n",
        "#         loss.backward()\n",
        "\n",
        "#         if (batch_idx + 1) % accumulation_steps == 0:\n",
        "#             optimizer.step()\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#         train_loss += loss.item()\n",
        "\n",
        "#     # After each epoch, check validation loss\n",
        "#     model.eval()\n",
        "#     val_loss = 0\n",
        "#     with torch.no_grad():\n",
        "#       for batch_data in val_loader:\n",
        "#           gt_imgs = batch_data['gt'].to(device)\n",
        "#           lq_imgs = batch_data['lq'].to(device)\n",
        "#           sr_imgs = model(lq_imgs)  # Super-resolve the low-quality images\n",
        "#           sr_imgs_resized = F.interpolate(sr_imgs, size=(gt_imgs.size(2), gt_imgs.size(3)), mode='bilinear', align_corners=False)\n",
        "#           val_loss += criterion(sr_imgs_resized, gt_imgs).item()\n",
        "\n",
        "#     val_loss /= len(val_loader)\n",
        "\n",
        "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader):.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "#     # Early stopping logic\n",
        "#     if val_loss < best_loss:\n",
        "#         best_loss = val_loss\n",
        "#         early_stopping_counter = 0  # Reset counter\n",
        "#         # Save the model if it's the best so far\n",
        "#         torch.save(model.state_dict(), f\"/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/model_2_{val_loss}.pth\")\n",
        "#     else:\n",
        "#         early_stopping_counter += 1\n",
        "#         print(f\"No improvement in validation loss for {early_stopping_counter} epochs.\")\n",
        "#         if early_stopping_counter >= early_stopping_patience:\n",
        "#             print(\"Stopping early due to lack of improvement in validation loss.\")\n",
        "#             break  # Break out of the training loop\n",
        "\n",
        "# # Save the trained model\n",
        "# torch.save(model.state_dict(), f\"/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/model_2_{val_loss}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOVvylGcB1Gd"
      },
      "outputs": [],
      "source": [
        "print(sum(p.numel() for p in model.parameters()))\n",
        "# torch.save(model.state_dict(), f\"/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/model_2_{val_loss}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0EhnfkfKjfp"
      },
      "outputs": [],
      "source": [
        "first_item = next(iter(test_loader))\n",
        "print(first_item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ed0A_oex47iV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "18f639be-9cd7-46c5-8286-5bff6f3c8bf9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0f7fda537286>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/model_2_0.0049.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_in_ch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_out_ch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust parameters as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m                 return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1015\u001b[0m                              \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                              \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1366\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m             _internal=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    259\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "model_path = '/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/best_model_0.0034990164777264.pth'\n",
        "model = SRResNet(num_in_ch=3, num_out_ch=3, num_feat=32, num_block=8, upscale=4)  # Adjust parameters as needed\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/outputs'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "brightness_factor = 1.5\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        input_tensor = data['gt'].to(device)\n",
        "        image_paths = data['gt_path']\n",
        "        print(f\"Processing images: {image_paths}\")\n",
        "\n",
        "        output_tensor = model(input_tensor)\n",
        "\n",
        "        for j, (single_img_tensor, image_path) in enumerate(zip(output_tensor, image_paths)):\n",
        "            single_img = single_img_tensor.cuda().squeeze(0)\n",
        "            # single_img = TF.adjust_brightness(single_img, brightness_factor)\n",
        "            base_name = os.path.basename(image_path).split('.')[0]\n",
        "            print(f\"Saving image: {base_name}.png\")\n",
        "            save_image(single_img, os.path.join(output_dir, f'{base_name}.png'))\n",
        "\n",
        "print(f\"Super-resolution images are saved in {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRi64Gz834Eh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/NTU 2023-2024/Advanced Computer Vision Projects/SuperResolution/outputs'\n",
        "base_name = 'submission'\n",
        "\n",
        "zip_filename = f\"{base_name}.zip\"\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for root, dirs, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            zipf.write(file_path, arcname=os.path.basename(file_path))\n",
        "\n",
        "print(f\"Images are successfully compressed into {zip_filename}. You can download it for submission.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}